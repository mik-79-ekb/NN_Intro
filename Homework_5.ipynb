{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Практическое задание:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Домашнее задание\n",
    "1. Попробуйте изменить параметры нейронной сети, работающей с датасетом imdb, либо\n",
    "нейронной сети, работающей airline-passengers (она прилагается вместе с датасетом к\n",
    "уроку в виде отдельного скрипта) так, чтобы улучшить её точность. Приложите анализ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB reviews (keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "\n",
    "# обрезание текстов после данного количества слов (среди top max_features наиболее используемые слова)\n",
    "maxlen = 100\n",
    "batch_size = 60 # увеличьте значение для ускорения обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n"
     ]
    }
   ],
   "source": [
    "print('Загрузка данных...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 19193,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 10311,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 12118,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the word index file mapping words to indices\n",
    "word_index = imdb.get_word_index()\n",
    "# Reverse the word index to obtain a dict mapping indices to words\n",
    "inverted_word_index = dict((i, word) for (word, i) in word_index.items())\n",
    "# Decode the first sequence in the dataset\n",
    "decoded_sequence = \" \".join(inverted_word_index[i] for i in x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 100)\n",
      "x_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Embedding(max_features, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Построение модели...\n"
     ]
    }
   ],
   "source": [
    "print('Построение модели...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 256))\n",
    "model.add(GRU(256, dropout=0.25, recurrent_dropout=0.25))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процесс обучения...\n",
      "Epoch 1/2\n",
      "417/417 [==============================] - 405s 964ms/step - loss: 0.4528 - accuracy: 0.7799 - val_loss: 0.4177 - val_accuracy: 0.8082\n",
      "Epoch 2/2\n",
      "417/417 [==============================] - 393s 942ms/step - loss: 0.2407 - accuracy: 0.9051 - val_loss: 0.3549 - val_accuracy: 0.8521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6932a4b20>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Процесс обучения...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=2, # увеличьте при необходимости\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 60s 143ms/step - loss: 0.3549 - accuracy: 0.8521\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат базовой сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Результат при тестировании: 0.366315633058548\n",
    "#Тестовая точность: 0.8381999731063843"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат доработанной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат при тестировании: 0.3548852801322937\n",
      "Тестовая точность: 0.8521199822425842\n"
     ]
    }
   ],
   "source": [
    "print('Результат при тестировании:', score)\n",
    "print('Тестовая точность:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Были изменены:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- увеличена длина текста;  \n",
    "- увеличено количество бачей;\n",
    "- увеличено количество нейронов в слоях;\n",
    "- была изменена архитектура нейронной сети;\n",
    "- увеличен размер дропаута и рекурентного дропаута;\n",
    "- незначительно увеличено количество эпох обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Попробуйте изменить параметры нейронной сети, генерирующей текст таким образом,\n",
    "чтобы добиться генерации как можно более осмысленного текста. Пришлите лучший\n",
    "текст из получившихся и опишите предпринятые для его получения действия. Можно\n",
    "использовать текст другого произведения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xLGyQjYG3eq"
   },
   "source": [
    "# Генерация текста на основе книжки «Алиса в стране чудес»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "99v6TBSqHBjU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построчное чтение из примера с текстом \n",
    "with open(\"alice_in_wonderland.txt\", 'rb') as _in:\n",
    "    lines = []\n",
    "    for line in _in:\n",
    "        line = line.strip().lower().decode(\"ascii\", \"ignore\")\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "text = \" \".join(lines)\n",
    "chars = set(text)\n",
    "nb_chars = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для удобства выберете фиксированную длину последовательность 10 символов \n",
    "SEQLEN, STEP = 20, 1\n",
    "input_chars, label_chars = [], []\n",
    "\n",
    "# конвертация data в серии разных SEQLEN-length субпоследовательностей\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i: i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FWqwrcHiH6gw"
   },
   "outputs": [],
   "source": [
    "# установка ряда метапамертров  для нейронной сети и процесса тренировки\n",
    "BATCH_SIZE, HIDDEN_SIZE = 128, 256\n",
    "NUM_ITERATIONS = 15 # 25 должно быть достаточно\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание индекса символов и reverse mapping чтобы передвигаться между значениями numerical\n",
    "# ID and a specific character. The numerical ID will correspond to a column\n",
    "# ID и определенный символ. Numerical ID будет соответсвовать колонке\n",
    "# число при использовании one-hot кодировки для представление входов символов\n",
    "char2index = {c: i for i, c in enumerate(chars)}\n",
    "index2char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-c8f27ba87c4d>:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
      "<ipython-input-16-c8f27ba87c4d>:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "# Вычисление one-hot encoding входных последовательностей X и следующего символа (the label) y\n",
    "\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158763, 20, 55)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    GRU(  # вы можете изменить эту часть на LSTM или SimpleRNN, чтобы попробовать альтернативы\n",
    "        HIDDEN_SIZE,\n",
    "        return_sequences=False,\n",
    "        input_shape=(SEQLEN, nb_chars),\n",
    "        unroll=True\n",
    "    )\n",
    ")\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsGE7YUdITrA",
    "outputId": "7e54fc46-8b4d-498b-ec84-0399313d11f3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Итерация #: 0\n",
      "1241/1241 [==============================] - 85s 62ms/step - loss: 2.2189\n",
      "Генерация из посева: oss-examine this wit\n",
      "oss-examine this with and the was a and the was a and the was a and the was a and the was a and the was a and the was a and the was a and the was a and the was a and the was a and the was a and the was a and the was a an==================================================\n",
      "Итерация #: 1\n",
      "1241/1241 [==============================] - 78s 63ms/step - loss: 1.7839\n",
      "Генерация из посева: nk of what work it w\n",
      "nk of what work it was the project gutenberg-tm all she was the project gutenberg-tm all she was the project gutenberg-tm all she was the project gutenberg-tm all she was the project gutenberg-tm all she was the project ==================================================\n",
      "Итерация #: 2\n",
      "1241/1241 [==============================] - 81s 65ms/step - loss: 1.6024\n",
      "Генерация из посева: loomily: then he dip\n",
      "loomily: then he diple the gryphon was so the gryphon was so the gryphon was so the gryphon was so the gryphon was so the gryphon was so the gryphon was so the gryphon was so the gryphon was so the gryphon was so the gry==================================================\n",
      "Итерация #: 3\n",
      "1241/1241 [==============================] - 83s 67ms/step - loss: 1.4748\n",
      "Генерация из посева: ry the whole cause, \n",
      "ry the whole cause, and the dormouse she was the reason the project gutenberg the reason the project gutenberg the reason the project gutenberg the reason the project gutenberg the reason the project gutenberg the reason==================================================\n",
      "Итерация #: 4\n",
      "1241/1241 [==============================] - 83s 67ms/step - loss: 1.3777\n",
      "Генерация из посева:  so used to queer th\n",
      " so used to queer the mouse of the sook of the sook of the sook of the sook of the sook of the sook of the sook of the sook of the sook of the sook of the sook of the sook of the sook of the sook of the sook of the sook ==================================================\n",
      "Итерация #: 5\n",
      "1241/1241 [==============================] - 83s 67ms/step - loss: 1.3000\n",
      "Генерация из посева: and had been of late\n",
      "and had been of late a little and the project gutenberg literary archive foundation of the some of the some of the some of the some of the some of the some of the some of the some of the some of the some of the some of t==================================================\n",
      "Итерация #: 6\n",
      "1241/1241 [==============================] - 88s 71ms/step - loss: 1.2339\n",
      "Генерация из посева: , wont you, wont you\n",
      ", wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you, wont you==================================================\n",
      "Итерация #: 7\n",
      "1241/1241 [==============================] - 84s 68ms/step - loss: 1.1764\n",
      "Генерация из посева: et you balanced an e\n",
      "et you balanced an explanation as she could get out of the stark of the stark of the stark of the stark of the stark of the stark of the stark of the stark of the stark of the stark of the stark of the stark of the stark==================================================\n",
      "Итерация #: 8\n",
      "1241/1241 [==============================] - 83s 67ms/step - loss: 1.1235\n",
      "Генерация из посева: nt the least idea wh\n",
      "nt the least idea white rabbit with the white rabbit was no had and roof look at the copyright holder, and she was a little going on the work of course, the mock turtle replied. theres no reason to get in the way of noth==================================================\n",
      "Итерация #: 9\n",
      "1241/1241 [==============================] - 79s 64ms/step - loss: 1.0741\n",
      "Генерация из посева: minute, nurse! but i\n",
      "minute, nurse! but i dont know what i say which was she was a little berow that she had a good deal of the gryphon as she said this as she had a good deal of the gryphon as she said this as she had a good deal of the gry==================================================\n",
      "Итерация #: 10\n",
      "1241/1241 [==============================] - 84s 68ms/step - loss: 1.0269\n",
      "Генерация из посева: when i was a child, \n",
      "when i was a child, in a louder as it was and all the time alice was so much of a learn of the court, and the other side of the some of the some of the some of the some of the some of the some of the some of the some of ==================================================\n",
      "Итерация #: 11\n",
      "1241/1241 [==============================] - 82s 66ms/step - loss: 0.9822\n",
      "Генерация из посева:  tone: sit down, bot\n",
      " tone: sit down, both of eating and distribute or the ears.  i can really made a really sure when the mock turtle parted to think that she had not come to the other side of the some of the some of the some of the some of==================================================\n",
      "Итерация #: 12\n",
      "1241/1241 [==============================] - 81s 65ms/step - loss: 0.9398\n",
      "Генерация из посева: er, as he found it m\n",
      "er, as he found it must be newving to the confreat ten so that she had not to herself, and she was now and then she had not come to the other side of the hatter, and then she had not come to the other side of the hatter,==================================================\n",
      "Итерация #: 13\n",
      "1241/1241 [==============================] - 80s 64ms/step - loss: 0.8990\n",
      "Генерация из посева: ed out, and, by the \n",
      "ed out, and, by the trial contemptoout it was and straightened against the poor little chiling in the same was she was so much at all rather a confusion, the mock turtle seemed to be no use in the same thing as if it was==================================================\n",
      "Итерация #: 14\n",
      "1241/1241 [==============================] - 51267s 41s/step - loss: 0.8617\n",
      "Генерация из посева: ave somebody to talk\n",
      "ave somebody to talk nothing of the great hurry. nothing she was going on, went on, you can do nothing every now, she added in a soldier or oneners and the trees has for seem to come back again, and all the time he was a"
     ]
    }
   ],
   "source": [
    "# выполнение серий тренировочных и демонстрационных итераций \n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "\n",
    "    # для каждой итерации запуск передачи данных в модель \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Итерация #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "\n",
    "    # Select a random example input sequence.\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "\n",
    "    # для числа шагов предсказаний использование текущей тренируемой модели \n",
    "    # конструирование one-hot encoding для тестирования input и добавление предсказания.\n",
    "    print(\"Генерация из посева: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "\n",
    "        # здесь one-hot encoding.\n",
    "        X_test = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            X_test[0, j, char2index[ch]] = 1\n",
    "\n",
    "        # осуществление предсказания с помощью текущей модели.\n",
    "        pred = model.predict(X_test, verbose=0)[0]\n",
    "        y_pred = index2char[np.argmax(pred)]\n",
    "\n",
    "        # вывод предсказания добавленного к тестовому примеру \n",
    "        print(y_pred, end=\"\")\n",
    "\n",
    "        # инкрементация тестового примера содержащего предсказание\n",
    "        test_chars = test_chars[1:] + y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CNR_gBGoIZUN",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158763, 55)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат базовой сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Итерация #: 9\n",
    "#1241/1241 [==============================] - 17s 13ms/step - loss: 1.3375\n",
    "#Генерация из посева:  some chan\n",
    "# some changed in the little with the project gutenberg-tm electronic work in the little with the project guten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат доработанной сети:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итерация #: 14  \n",
    "1241/1241 [==============================] - 51267s 41s/step - loss: 0.8617  \n",
    "Генерация из посева: ave somebody to talk  \n",
    "ave somebody to talk nothing of the great hurry. nothing she was going on, went on, you can do nothing every now, she added in a soldier or oneners and the trees has for seem to come back again, and all the time he was a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Были изменены:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- длина последовательности (SEQLEN);  \n",
    "- количество нейронов скрытого слоя (HIDDEN_SIZE);  \n",
    "- количество итераций (NUM_ITERATIONS);\n",
    "- количество предсказаний за эпоху(NUM_PREDS_PER_EPOCH);\n",
    "- другие мелкие доработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Lesson 5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
